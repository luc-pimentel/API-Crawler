{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Creating Data Lakes**\n",
    "\n",
    "### **Introduction**\n",
    "\n",
    "Data lakes are centralized repositories that allow you to store all your structured and unstructured data at any scale.\n",
    "\n",
    "They are helpful for you to store, manage, and analyze large volumes of data.\n",
    "\n",
    "In this documentation, we will explore how the `api_crawler` module creates data lakes by automatically logging every interaction with data sources.\n",
    "\n",
    "### **Logging Function Interactions**\n",
    "\n",
    "The `api_crawler` module creates a datalake for every function that has the `log_io_to_json` decorator on top of it.\n",
    "\n",
    "This decorator automatically logs the inputs, outputs, execution time, and errors (if any) of a function and saves it to a JSON file by the name of the function.\n",
    "\n",
    "**Note**: The JSON file will be saved in the directory specified by the `LAKES_BASE_DIR` environment variable. This variable can be set in the `.env` file or as a global variable using `os.environ['LAKES_BASE_DIR']`.\n",
    "\n",
    "\n",
    "### **Decorator: `log_io_to_json`**\n",
    "\n",
    "#### **Purpose**\n",
    "\n",
    "The `log_io_to_json` decorator logs the input and output of a function to a JSON file. This helps in creating a data lake by capturing all interactions with data sources.\n",
    "\n",
    "The goal here was to be versatile in the structrure of the lake, all the while logging all data that may be useful to store.\n",
    "\n",
    "#### **How It Works**\n",
    "\n",
    "1. **Unique Identifier**: Generates a unique identifier for each function call.\n",
    "2. **Timing**: Captures the start and end time of the function execution.\n",
    "3. **Function Execution**: Executes the original function and captures its output. If an error occurs, it logs the error.\n",
    "4. **Argument Binding**: Binds the passed arguments to the function's signature and serializes them.\n",
    "5. **Logging**: Stores the input, output, and timing information in a JSON file.\n",
    "\n",
    "## **Example**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from api_crawler import LinkedInAPI\n",
    "\n",
    "linkedin_api = LinkedInAPI()\n",
    "\n",
    "job_posting_data = linkedin_api.get_job_postings_data('Data Analyst', location='New York', n_listings = 2, days_ago=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The call to this function, along with its inputs, outputs, and other details, will be saved in the file LinkedInAPI_get_job_postings_data.json located in the specified folder.\n",
    "\n",
    "In this example, the output is as follows:\"\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"id\": \"c58afbdb-0535-4bbd-a9a5-a8eae845ed64\",\n",
    "  \"start_time\": \"2024-06-14T11:46:05\",\n",
    "  \"end_time\": \"2024-06-14T11:46:40\",\n",
    "  \"input\": {\n",
    "    \"args\": {\n",
    "      \"self\": \"<api_crawler.data_sources.linked_in.LinkedInAPI object>\",\n",
    "      \"search_query\": \"Data Analyst\",\n",
    "      \"n_listings\": 30,\n",
    "      \"kwargs\": {\n",
    "        \"location\": \"New York\",\n",
    "        \"days_ago\": 7\n",
    "      }\n",
    "    }\n",
    "  },\n",
    "  \"output\": [\n",
    "    {\n",
    "      \"title\": \"Data Analyst\",\n",
    "      \"company\": \"Stripe\",\n",
    "      \"location\": \"New York, United States\",\n",
    "      \"time\": \"2024-06-12\",\n",
    "      \"link\": \"https://www.linkedin.com/jobs/view/data-analyst-at-stripe-3824634046?position=1&pageNum=0&refId=JrOmBu3qWObVHJInLHlD%2BQ%3D%3D&trackingId=Qcv8NYThUZK1APMjmy4zYQ%3D%3D&trk=public_jobs_jserp-result_search-card\"\n",
    "    },\n",
    "    {\n",
    "      \"title\": \"Data Analyst\",\n",
    "      \"company\": \"New York Islanders\",\n",
    "      \"location\": \"Floral Park, NY\",\n",
    "      \"time\": \"2024-06-12\",\n",
    "      \"link\": \"https://www.linkedin.com/jobs/view/data-analyst-at-new-york-islanders-3948895425?position=2&pageNum=0&refId=JrOmBu3qWObVHJInLHlD%2BQ%3D%3D&trackingId=mj%2FQFvrETnNX%2FTX8oKiJ9Q%3D%3D&trk=public_jobs_jserp-result_search-card\"\n",
    "    }\n",
    "  ]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Accessing Your Logs**\n",
    "\n",
    "To easily access and read the logs created by the `log_io_to_json` decorator, you can use the `read_log` utility function. This function reads the content of a specified JSON file and returns the data in a list of dictionaries.\n",
    "\n",
    "### **How to Use `read_log`**\n",
    "\n",
    "1. **Import the Function**: First, ensure you import the `read_log` function from the `api_crawler.data_lake` module.\n",
    "2. **Specify the File Path**: Provide the path to the JSON file you want to read. This path should be relative to the base directory specified by the `LAKES_BASE_DIR` environment variable.\n",
    "3. **Read the Log**: Call the `read_log` function with the file path to get the logged data.\n",
    "\n",
    "### **Example**\n",
    "\n",
    "Here is an example of how to use the `read_log` function:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 'c58afbdb-0535-4bbd-a9a5-a8eae845ed64',\n",
       "  'start_time': '2024-06-14T11:46:05',\n",
       "  'end_time': '2024-06-14T11:46:40',\n",
       "  'input': {'args': {'self': '<api_crawler.data_sources.linked_in.LinkedInAPI object at 0x7be546563430>',\n",
       "    'search_query': 'Data Analyst',\n",
       "    'n_listings': 30,\n",
       "    'kwargs': {'location': 'New York', 'days_ago': 7}}},\n",
       "  'output': [{'title': 'Data Analyst',\n",
       "    'company': 'Stripe',\n",
       "    'location': 'New York, United States',\n",
       "    'time': '2024-06-12',\n",
       "    'link': 'https://www.linkedin.com/jobs/view/data-analyst-at-stripe-3824634046?position=1&pageNum=0&refId=JrOmBu3qWObVHJInLHlD%2BQ%3D%3D&trackingId=Qcv8NYThUZK1APMjmy4zYQ%3D%3D&trk=public_jobs_jserp-result_search-card'},\n",
       "   {'title': 'Data Analyst',\n",
       "    'company': 'New York Islanders',\n",
       "    'location': 'Floral Park, NY',\n",
       "    'time': '2024-06-12',\n",
       "    'link': 'https://www.linkedin.com/jobs/view/data-analyst-at-new-york-islanders-3948895425?position=2&pageNum=0&refId=JrOmBu3qWObVHJInLHlD%2BQ%3D%3D&trackingId=mj%2FQFvrETnNX%2FTX8oKiJ9Q%3D%3D&trk=public_jobs_jserp-result_search-card'}]}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from api_crawler.data_lake import read_log\n",
    "\n",
    "read_log(f'{base_file_path}/LinkedInAPI_get_job_postings_data.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Conclusion**\n",
    "\n",
    "By using the `log_io_to_json` decorator, you will effortlessly log and store function interactions. Thus allowing you to leverage the full potential of your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
