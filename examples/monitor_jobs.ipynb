{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monitoring Job Listings\n",
    "\n",
    "The goal of this notebook is to show you how the api_crawler library works.\n",
    "\n",
    "For this example, let's focus on monitoring job posts. We will gather data from the top three job boards. First, we need to import the necessary modules from the api_crawler library and create their instances.\n",
    "\n",
    "While we are at it, let's also set a job title to monitor and create the API instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from api_crawler import LinkedInAPI, Glassdoor, IndeedAPI\n",
    "\n",
    "\n",
    "job_role_to_monitor = 'Data Analyst'\n",
    "\n",
    "\n",
    "linked_in_api = LinkedInAPI()\n",
    "\n",
    "glassdoor_api = Glassdoor()\n",
    "\n",
    "indeed_api = IndeedAPI()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, if we want to scrape the job listings, all we have to do is use the get_job_postings_date method of the appropriate object. And then, we'll get a list of all the job ads in the format we need.\n",
    "\n",
    "Just as in the examples below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'Data Analyst, Lyft Media',\n",
       " 'subtitle': 'Lyft',\n",
       " 'location': 'New York, NY',\n",
       " 'link': 'https://www.linkedin.com/jobs/view/data-analyst-lyft-media-at-lyft-3941227696?position=1&pageNum=0&refId=LcCyONwTMBZKZ53egbJo5w%3D%3D&trackingId=iavJSyRMx5e5dRtxyJmAuw%3D%3D&trk=public_jobs_jserp-result_search-card',\n",
       " 'list_date': '2024-06-03'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linked_in_jobs_data = linked_in_api.get_job_postings_data(job_role_to_monitor)\n",
    "linked_in_jobs_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'company_name': 'Grammarly, Inc.',\n",
       " 'title': 'People Consultant',\n",
       " 'location': 'United States',\n",
       " 'salary': '$169K\\xa0(Employer est.)',\n",
       " 'snippet': '401(k) and RRSP matching. Our People Partner team provides strategic business partnerships and coaching and develops people-related solutions to meet critical……\\n\\nSkills: Management\\n      \\n',\n",
       " 'date': '2d',\n",
       " 'link': 'https://www.glassdoor.com/job-listing/people-consultant-grammarly-inc-JV_KO0,17_KE18,31.htm?jl=1009312643258'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glassdoor_jobs_data = glassdoor_api.get_job_postings_data(job_role_to_monitor, close=False)\n",
    "glassdoor_jobs_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'job_title': 'Data Analyst - Remote',\n",
       " 'company_name': 'Hallmark Cards',\n",
       " 'job_location': 'Remote in Missouri',\n",
       " 'snippet': '\\nWe focus on using data to understand performance trends and our consumers, leveraging a vast number of data sources and types.\\n41 CFR 60-1.35(c).\\n',\n",
       " 'date': 'PostedToday',\n",
       " 'link': 'https://www.indeed.com/rc/clk?jk=8e131462b2aa86b9&bb=1NNTJSvrikyTsSghr8ZdTU5UU3AEsv1AAD29SiT7AE4G5oEcyH4Q6IcDd4xxne-UQzMgV17dSqs-IEdvpS2mEahOAcLYToyyl9W6ZJQsXIB1Uw9FUu8-aTUQJRghFuuu&xkcb=SoBo67M3A802-CSKBx0LbzkdCdPP&fccid=f6b7f1c44b44197c&vjs=3'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indeed_jobs_data = indeed_api.get_job_postings_data(job_role_to_monitor, close=False)\n",
    "indeed_jobs_data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Your Own Data Lakes\n",
    "\n",
    "Now, in addition to fetching data, the api_crawler library also stores the results in a data lake. You can find this data lake in the folder specified by the LAKES_BASE_DIR variable in the .env file.\n",
    "\n",
    "\n",
    "The goal here is to help you keep all the data you gather and create your own databases of external data. Feel free to use this data to create or fine-tune your own AI models, monitor specific information outside your organization.\n",
    "\n",
    "Furthermore, the JSON lakes provide detailed information about your request. This includes the time it was made, the arguments passed to it, and any other data that might be useful for you later. Once again, the goal is to help you build your own databases of external data and explore the data as you wish.\n",
    "\n",
    "\n",
    "----\n",
    "\n",
    "\n",
    "Now, on the example above, we've created jobs to monitor only one job listing.\n",
    "\n",
    "But if you want to keep an eye on many listings at once, you can easily do so by using a list of job roles. As in the example below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_roles_to_monitor = ['Data Analyst', 'Data Scientist', 'Data Engineer']\n",
    "\n",
    "glassdoor_api = Glassdoor()\n",
    "indeed_api = IndeedAPI()\n",
    "\n",
    "linked_in_jobs_data = []\n",
    "glassdoor_jobs_data = []\n",
    "indeed_jobs_data = []\n",
    "\n",
    "\n",
    "for job_role in job_roles_to_monitor:\n",
    "    linked_in_jobs_data.extend(linked_in_api.get_job_postings_data(job_role))\n",
    "    glassdoor_jobs_data.extend(glassdoor_api.get_job_postings_data(job_role, close=False))\n",
    "    indeed_jobs_data.extend(indeed_api.get_job_postings_data(job_role, close=False))\n",
    "\n",
    "glassdoor_api.close()\n",
    "indeed_api.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarize With AI\n",
    "\n",
    "One of the biggest uses for fetching and scraping data is to have AI summarize it and keep track of real-time events without wasting time.\n",
    "\n",
    "And to do this with the api_crawler library, you'd simply need to add an extra step and have AI summarize the information. You can do this in two ways: either right after fetching the data or using the data stored in the data lakes.\n",
    "\n",
    "And as you can see in the example below, the AI summarization step is probably the easiest. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Suggest skills to land the highest paying jobs\n",
    "\n",
    "prompt = '''\n",
    "Based on the job postings below, please suggest me the skills that are most important to land the highest paying jobs.\n",
    "\n",
    "####\n",
    "\n",
    "{data}\n",
    "\n",
    "####\n",
    "\n",
    "Begin!\n",
    "'''\n",
    "\n",
    "\n",
    "data = \"##### \\n\\n\".join([f\"Title: {job['title']}; Snippet: {job['snippet']}\" for job in glassdoor_jobs_data[:10]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI response:\n",
      "\n",
      " Based on the job postings provided, the skills that appear to be most important for landing high-paying jobs are:\n",
      "\n",
      "1. **Research Skills:** Research skills are mentioned in multiple job postings, such as quantitative research, veterinary talent research, and data analysis. Being proficient in research methodologies and tools like Stata, Boolean searches, and data analysis skills is valuable.\n",
      "\n",
      "2. **Communication Skills:** Strong communication skills are crucial for roles like telemarketer, order filler, and accounts payable clerk. Being able to communicate effectively with customers, vendors, and team members is a highly sought-after skill.\n",
      "\n",
      "3. **Microsoft Excel:** Proficiency in Microsoft Excel is mentioned in several job postings like business development representative, data entry coordinator, and part-time remote research assistant. Excel skills are often essential for data analysis, reporting, and organizational tasks.\n",
      "\n",
      "4. **Customer Service:** Customer service skills are highlighted in roles like data entry coordinator and accounts payable clerk. Providing excellent customer service is important for maintaining positive relationships with clients and vendors.\n",
      "\n",
      "5. **Sales Experience:** Roles such as business development representative emphasize the need for sales experience, especially in B2B settings. Experience in sales, phone etiquette, and telemarketing can be valuable skills for securing high-paying jobs.\n",
      "\n",
      "6. **Technical Skills:** Some job postings mention specific technical skills like using phone systems, troubleshooting tech issues, and software proficiency, such as Sage. Being tech-savvy and having the ability to navigate various systems and software can be beneficial.\n",
      "\n",
      "By honing these skills and gaining experience in relevant areas, you can increase your chances of landing high-paying jobs in fields like research, customer service, sales, and data analysis.\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI(api_key='YOUR_OPENAI_API_KEY')\n",
    "\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": prompt.format(data=data)}\n",
    "  ]\n",
    ")\n",
    "\n",
    "\n",
    "ai_response = response.choices[0].message.content\n",
    "\n",
    "print(f'AI response:\\n\\n {ai_response}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this notebook, we demonstrated how to use the `api_crawler` library to monitor job listings from top job boards like LinkedIn, Glassdoor, and Indeed. We covered the steps to set up API instances, fetch job postings, and store the data in a data lake for further analysis. Additionally, we explored how to use AI to summarize job data and extract valuable insights.\n",
    "\n",
    "By leveraging these tools, you can efficiently track job market trends and make data-driven decisions to enhance your career or business strategies.\n",
    "\n",
    "Please go ahead and explore other examples and experiment with the `api_crawler` library to unlock its full potential."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
